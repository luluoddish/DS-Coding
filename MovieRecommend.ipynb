{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieRecommend.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqiTrTU3e9Y9MMZ3oaTORr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luluoddish/DS-Coding/blob/main/MovieRecommend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bShTP-NYYw2Z",
        "outputId": "95e06848-42f9-4c0f-fb18-1d589f3662ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 7.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=ea1b5991234e7d9b4fa270f12f4c08ffbe0f724281c28b666f3e77c2d0009b39\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ySfBBm8Z2Z5",
        "outputId": "3a4753f4-20f4-4e04-d89a-2f94c3b13434"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "import pyspark\n",
        "from pyspark import SparkContext, SparkConf\n"
      ],
      "metadata": {
        "id": "A7y1lA_kZ6XW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "EN-iN0p9ZnrL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row"
      ],
      "metadata": {
        "id": "_hdyd_vRZEe0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "lines = spark.read.text(\"sample_movielens_ratings.txt\").rdd\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIH5VETfZG9R",
        "outputId": "fc1e1708-98f6-4808-cfe2-01c6622a648b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MapPartitionsRDD[4] at javaToPython at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JCKoZkK8lXj",
        "outputId": "9287adc3-bc37-40e7-a9a9-5cd7df595715"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='0::2::3::1424380312'),\n",
              " Row(value='0::3::1::1424380312'),\n",
              " Row(value='0::5::2::1424380312'),\n",
              " Row(value='0::9::4::1424380312'),\n",
              " Row(value='0::11::1::1424380312')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
        "parts.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB1sZmU1Zd25",
        "outputId": "8c11274e-edb5-4c07-ef97-41222335eac4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['0', '2', '3', '1424380312'],\n",
              " ['0', '3', '1', '1424380312'],\n",
              " ['0', '5', '2', '1424380312'],\n",
              " ['0', '9', '4', '1424380312'],\n",
              " ['0', '11', '1', '1424380312']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),rating=float(p[2]), timestamp=int(p[3])))\n",
        "ratings = spark.createDataFrame(ratingsRDD)"
      ],
      "metadata": {
        "id": "wUhAe3sx9FC8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.printSchema()\n",
        "ratings.count()\n",
        "ratings.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep-y2OWVazmB",
        "outputId": "f0398a87-0b02-46e5-f6a0-90ccd6def54e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: long (nullable = true)\n",
            " |-- movieId: long (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: long (nullable = true)\n",
            "\n",
            "+------+-------+------+----------+\n",
            "|userId|movieId|rating| timestamp|\n",
            "+------+-------+------+----------+\n",
            "|     0|      2|   3.0|1424380312|\n",
            "|     0|      3|   1.0|1424380312|\n",
            "|     0|      5|   2.0|1424380312|\n",
            "|     0|      9|   4.0|1424380312|\n",
            "|     0|     11|   1.0|1424380312|\n",
            "+------+-------+------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check missing values\n",
        "from pyspark.sql.functions import isnan, when, count, col, translate\n",
        "ratings.select([count(when(col(c).isNull(), c)).alias(c) for c in ratings.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-f_69JwcFOZ",
        "outputId": "9f3ced5f-e1c2-43b1-e386-b2deb9ef477f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     0|      0|     0|        0|\n",
            "+------+-------+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(training, test) = ratings.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "jbV2i1_0aogH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Collaborative filtering**"
      ],
      "metadata": {
        "id": "xqv03T52_rO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",coldStartStrategy=\"drop\")\n",
        "model = als.fit(training)"
      ],
      "metadata": {
        "id": "eqP9mfhWa-e0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgRT4Db7bDEF",
        "outputId": "2cd9f865-3c16-4fd1-d027-f93ac7932cc5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 1.774057289280048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate top 10 movie recommendations for each user\n",
        "userRecs = model.recommendForAllUsers(10)\n",
        "# Generate top 10 user recommendations for each movie\n",
        "movieRecs = model.recommendForAllItems(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNFTAIOgbF5r",
        "outputId": "6554c116-5be2-4859-8112-5332951b2473"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate top 10 movie recommendations for a specified set of users\n",
        "users = ratings.select(als.getUserCol()).distinct().limit(2)\n",
        "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
        "# Generate top 10 user recommendations for a specified set of movies\n",
        "movies = ratings.select(als.getItemCol()).distinct().limit(2)\n",
        "movieSubSetRecs = model.recommendForItemSubset(movies, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QPNG3VlbSVi",
        "outputId": "55f14538-040d-4d8d-af7e-8aaa1f282477"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "userRecs.show()\n",
        "movieRecs.show()\n",
        "userSubsetRecs.show()\n",
        "movieSubSetRecs.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGncEzCzbTT7",
        "outputId": "29a522f5-583d-46b8-a1a7-81787bfda8d7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|    20|[{22, 4.8757463},...|\n",
            "|    10|[{22, 4.0335984},...|\n",
            "|     0|[{9, 3.828909}, {...|\n",
            "|     1|[{30, 5.8832297},...|\n",
            "|    21|[{53, 4.9282904},...|\n",
            "|    11|[{32, 5.0709496},...|\n",
            "|    12|[{64, 4.99572}, {...|\n",
            "|    22|[{93, 5.1425695},...|\n",
            "|     2|[{93, 5.182481}, ...|\n",
            "|    13|[{93, 3.8537502},...|\n",
            "|     3|[{95, 4.914546}, ...|\n",
            "|    23|[{46, 6.7593083},...|\n",
            "|     4|[{62, 3.9653468},...|\n",
            "|    24|[{47, 6.0930214},...|\n",
            "|    14|[{29, 5.200471}, ...|\n",
            "|     5|[{46, 7.1353745},...|\n",
            "|    15|[{46, 4.847082}, ...|\n",
            "|    25|[{27, 4.124669}, ...|\n",
            "|    26|[{94, 6.5673876},...|\n",
            "|     6|[{25, 3.9760509},...|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+--------------------+\n",
            "|movieId|     recommendations|\n",
            "+-------+--------------------+\n",
            "|     20|[{17, 4.89197}, {...|\n",
            "|     40|[{2, 3.774947}, {...|\n",
            "|     10|[{17, 4.1062326},...|\n",
            "|     50|[{23, 4.450046}, ...|\n",
            "|     80|[{3, 4.1307096}, ...|\n",
            "|     70|[{8, 4.533949}, {...|\n",
            "|     60|[{7, 3.955196}, {...|\n",
            "|     90|[{16, 5.1474624},...|\n",
            "|     30|[{1, 5.8832297}, ...|\n",
            "|      0|[{10, 2.4676464},...|\n",
            "|     31|[{12, 3.8137937},...|\n",
            "|     81|[{28, 5.029352}, ...|\n",
            "|     91|[{23, 4.371205}, ...|\n",
            "|      1|[{15, 3.9181588},...|\n",
            "|     41|[{8, 4.2617664}, ...|\n",
            "|     61|[{6, 2.9810307}, ...|\n",
            "|     51|[{3, 4.5166526}, ...|\n",
            "|     21|[{26, 3.0344522},...|\n",
            "|     11|[{18, 4.0403357},...|\n",
            "|     71|[{2, 3.0985165}, ...|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+--------------------+\n",
            "|userId|     recommendations|\n",
            "+------+--------------------+\n",
            "|    26|[{94, 6.5673876},...|\n",
            "|    29|[{46, 4.937483}, ...|\n",
            "+------+--------------------+\n",
            "\n",
            "+-------+--------------------+\n",
            "|movieId|     recommendations|\n",
            "+-------+--------------------+\n",
            "|     26|[{8, 3.820621}, {...|\n",
            "|     29|[{14, 5.200471}, ...|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}